{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'>IBM Datas Science &ndash; Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Traffic accident severity prediction by Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'>Danh Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (1,2,5,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Imported\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv(\"../Capstone_Data/NCDB_1999_to_2014.csv\")\n",
    "print(\"Data Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>C_MNTH</th>\n",
       "      <th>C_WDAY</th>\n",
       "      <th>C_HOUR</th>\n",
       "      <th>C_SEV</th>\n",
       "      <th>C_VEHS</th>\n",
       "      <th>C_CONF</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>...</th>\n",
       "      <th>V_ID</th>\n",
       "      <th>V_TYPE</th>\n",
       "      <th>V_YEAR</th>\n",
       "      <th>P_ID</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>P_PSN</th>\n",
       "      <th>P_ISEV</th>\n",
       "      <th>P_SAFE</th>\n",
       "      <th>P_USER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>1990</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>1987</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>1987</td>\n",
       "      <td>02</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>UU</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1986</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>UU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>UU</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNNN</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>05</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>UU</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_YEAR C_MNTH C_WDAY C_HOUR  C_SEV C_VEHS C_CONF C_RCFG C_WTHR C_RSUR  ...  \\\n",
       "0    1999      1      1     20      2     02     34     UU      1      5  ...   \n",
       "1    1999      1      1     20      2     02     34     UU      1      5  ...   \n",
       "2    1999      1      1     20      2     02     34     UU      1      5  ...   \n",
       "3    1999      1      1     08      2     01     01     UU      5      3  ...   \n",
       "4    1999      1      1     08      2     01     01     UU      5      3  ...   \n",
       "\n",
       "  V_ID V_TYPE V_YEAR P_ID P_SEX P_AGE P_PSN P_ISEV P_SAFE P_USER  \n",
       "0   01     06   1990   01     M    41    11      1     UU      1  \n",
       "1   02     01   1987   01     M    19    11      1     UU      1  \n",
       "2   02     01   1987   02     F    20    13      2     02      2  \n",
       "3   01     01   1986   01     M    46    11      1     UU      1  \n",
       "4   99     NN   NNNN   01     M    05    99      2     UU      3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5860405, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provides detail information of the accidents, grouping into logical groups, i.e. vehicle data, person data,... (details in drivingLegend.pdf). The target data that we want to predict is collision severity (C_SEV), which has 2 desired outcome: 1, 2 as fatal and non-fatal respectively.\n",
    "\n",
    "From these data, we will use different machine learning algorithm to predict the outcome of the accidents, based on our hypothesis. Details below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the vehicle data group, we hypothesize that the year model greatly affect the survivability of the accident. As the newer the vehicle, the better safety it has. A logistic regression is suitable for this as it provides the probability of fatality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h4>Vehicle data prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5860405, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get a sub-data frame consist of type, year model, severity\n",
    "vh_df = df[['V_TYPE', 'V_YEAR', 'C_SEV']]\n",
    "vh_df.head()\n",
    "vh_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non applicable data\n",
    "vh_df = vh_df[~vh_df['V_TYPE'].isin(['UU', 'QQ', 'NN', 'XX'])]\n",
    "vh_df = vh_df[~vh_df['V_YEAR'].isin(['UUUU', 'QQQQ', 'NNNN', 'XXXX'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5239333, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X, y for training\n",
    "X = vh_df[['V_TYPE', 'V_YEAR']].to_numpy()\n",
    "y = vh_df[['C_SEV']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.43221371, -1.19286724],\n",
       "       [-0.31628534, -1.61394269],\n",
       "       [-0.31628534, -1.61394269],\n",
       "       [-0.31628534, -1.75430118],\n",
       "       [-0.31628534, -2.03501814]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing dataset\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (3143599, 2) (3143599, 1)\n",
      "Test set: (2095734, 2) (2095734, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=42)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuda\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983419651539747"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (1571799, 2) (1571799, 1)\n",
      "Test set: (3667534, 2) (3667534, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuda\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9835167172274341"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.7, random_state=1234)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "# Applying Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "yhat = LR.predict(X_test)\n",
    "metrics.accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
